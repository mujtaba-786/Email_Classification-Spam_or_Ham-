# -*- coding: utf-8 -*-
"""Email_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-VDAaqMoi7CSOVB1AFhKtzQ6Ou2_TE-I
"""

from google.colab import files

file=files.upload()

import pandas as pd 
import io

df2=pd.read_excel(io.BytesIO(file['spam_or_ham.xlsx']),names=['spam_or_ham','Email'])

df2.head()

df2.tail()

df2.shape

df2.info()

df2.isnull().sum()

df2.info()

df2['spam_or_ham'].describe()

len(df2[df2['spam_or_ham']=='ham']), len(df2[df2['spam_or_ham']=='spam'])

ham_length=len(df2[df2['spam_or_ham']=='ham'])
spam_length=len(df2[df2['spam_or_ham']=='spam'])

print('Percentage of ham messages : ',round((((ham_length)/(ham_length+spam_length))*100),2))

print('Percentage of spam messages : ',round((((spam_length)/(ham_length+spam_length))*100),2))

import seaborn as sns

sns.countplot(df2['spam_or_ham'])

"""Clearly we observe that ham messages are more than spam messages"""



"""**FEATURE EXTRACTION OF EMAIL MESSAGES**"""

def lenn(sentence):
  
  len_exclude_space=0
  for i in sentence:
    if i!=' ':
      len_exclude_space+=1
  return len_exclude_space

df2['len_email']=df2['Email'].apply(lambda x: lenn(str(x)))

df2.head()

import string
string.punctuation

def punc_len(sentence):
  punc_lenn=0
  count=0

  for i in sentence:
    if i in string.punctuation:
      punc_lenn+=1
    if i!=' ':
      count+=1
  return round((punc_lenn/(count))*100,2)

df2['punc_per']=df2['Email'].apply(lambda x : punc_len(str(x)))

df2.head()

df2['spam_or_ham']=df2['spam_or_ham'].replace({'ham':0,'spam':1})

df2.head()

df2.corr()

import seaborn as sns

sns.heatmap(df2.corr())

sns.pairplot(df2)



"""**TRAINING USING ML MODELS**"""

X=df2.iloc[:,2:4]
Y=df2.iloc[:,0:1]

X.head()

Y.head()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=34)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

all_models=[LogisticRegression(),SVC(),GaussianNB(),DecisionTreeClassifier(),RandomForestClassifier(),GradientBoostingClassifier()]

from sklearn.metrics import accuracy_score, confusion_matrix

print('ACCURACY SCORE OF LOGISTIC REGRESSION : ')
for i in range(10):
  fitter=LogisticRegression()
  fitter.fit(x_train,y_train)
  b=fitter.predict(x_test)
  print(accuracy_score(b,y_test))

print('ACCURACY SCORE OF SVC : ')
for i in range(10):
  fitter=SVC()
  fitter.fit(x_train,y_train)
  b=fitter.predict(x_test)
  print(accuracy_score(b,y_test))

print('ACCURACY SCORE OF GaussianNB : ')
for i in range(10):
  fitter=GaussianNB()
  fitter.fit(x_train,y_train)
  b=fitter.predict(x_test)
  print(accuracy_score(b,y_test))

print('ACCURACY SCORE OF DecisionTree : ')
for i in range(10):
  fitter=DecisionTreeClassifier()
  fitter.fit(x_train,y_train)
  b=fitter.predict(x_test)
  print(accuracy_score(b,y_test))

print('ACCURACY SCORE OF RandomForest : ')
for i in range(10):
  fitter=RandomForestClassifier()
  fitter.fit(x_train,y_train)
  b=fitter.predict(x_test)
  print(accuracy_score(b,y_test))

print('ACCURACY SCORE OF GradientBoost : ')
for i in range(10):
  fitter=GradientBoostingClassifier()
  fitter.fit(x_train,y_train)
  b=fitter.predict(x_test)
  print(accuracy_score(b,y_test))

"""**HERE WE CAN INFER THAT RANDOMFOREST , XGBOOST AND DECISION TREE PERFORM WELL WITH HIGHEST ACCURACY OF 90.38%**"""

confusion_matrix(b,y_test)

